{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the topics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics.pairwise as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.externals import joblib\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"Kmeans7.model\")\n",
    "labels = model.labels_\n",
    "NUMBER_OF_CLUSTERS = 7\n",
    "categorized = [[\"START\"] for j in range(NUMBER_OF_CLUSTERS)]\n",
    "for j in range(NUMBER_OF_CLUSTERS):\n",
    "    print(categorized[labels[j]])\n",
    "NUMBER_OF_FILES = 51740\n",
    "files = [\"\"]*NUMBER_OF_FILES\n",
    "content = [\"\"]*NUMBER_OF_FILES\n",
    "for i in range(1, NUMBER_OF_FILES):\n",
    "    files[i] = open(\"clean/\"+str(10*i)+\".txt\", \"r\")\n",
    "    content[i] = files[i].read()\n",
    "    print(labels[i-1])\n",
    "    categorized[labels[i-1]].append(content[i])\n",
    "    files[i].close()\n",
    "\t\n",
    "for i in range(NUMBER_OF_CLUSTERS):\n",
    "    new_file = open(\"Kmeans7_clustered.files/\"+str(i)+ \".txt\", \"w+\")\n",
    "    for element in categorized[i][:50]:\n",
    "        new_file.write(element)\n",
    "        new_file.write(\"\\n\\n - - x - - \\n\\n\")\n",
    "    new_file.close()\n",
    "\n",
    "content = []\n",
    "for i in range(NUMBER_OF_CLUSTERS):\n",
    "    text = ' '.join(categorized[i])\n",
    "    content.append(text)\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(input = 'content', use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(content)\n",
    "tfidf_vectorizer_vectors.toarray()\n",
    "features = tfidf_vectorizer.get_feature_names()\n",
    "# print(features[i])\n",
    "tfidf_array_format = tfidf_vectorizer_vectors.toarray()\n",
    "\n",
    "#For understanding output\n",
    "for i in range(NUMBER_OF_CLUSTERS):\n",
    "    new_file = open(\"Kmeans7_clustered.files/\"+str(i)+ \".txt\", \"a\")\n",
    "    new_file.seek(0)\n",
    "    row = tfidf_array_format[i]\n",
    "    topn_ids = np.argsort(row)[::-1][:20]\n",
    "    # print(topn_ids)\n",
    "    # print(row[topn_ids[0]])\n",
    "    top_feats = [(features[j], row[j]) for j in topn_ids]\n",
    "    df = pd.DataFrame(top_feats, columns=['features', 'score'])\n",
    "    print(\"Top 30 words and scores in document: \")\n",
    "    print(df)\n",
    "    df.to_string(new_file)\n",
    "    new_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib/python3.7/site-packages/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics.pairwise as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.externals import joblib\n",
    "from joblib import dump\n",
    "\n",
    "NUMBER_OF_FILES = 51740\n",
    "\n",
    "# NUMBER_OF_FILES_test = 1\n",
    "# files_test = [\"\"]*NUMBER_OF_FILES_test\n",
    "# for i in range(NUMBER_OF_FILES_test):\n",
    "#     files_test[i] = open(str(i+1)+\".\", \"r\")\n",
    "# tfidf_vectorizer_test = TfidfVectorizer(input = 'file', use_idf=True)\n",
    "# tfidf_vectorizer_test_vectors=tfidf_vectorizer_test.fit_transform(files_test)\n",
    "files = [\"\"]*NUMBER_OF_FILES\n",
    "content = [\"\"]*NUMBER_OF_FILES\n",
    "for i in range(1, NUMBER_OF_FILES):\n",
    "    files[i] = open(\"clean/\"+str(10*i)+\".txt\", \"r\")\n",
    "    content[i] = files[i].read()\n",
    "    files[i].close()\n",
    "    # text = nltk.pos_tag(text)\n",
    "    # for j in range(len(text)):\n",
    "    # \tif(text[j][1].startswith(\"N\") or text[j][1].startswith(\"V\")): #Clustering only on nouns and verbs\n",
    "    # \t\tcontent[i] = content[i] + \" \"+ text[j][0]\n",
    "tfidf_vectorizer=TfidfVectorizer(input = 'content', use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(content)\n",
    "tfidf_vectorizer_vectors.toarray()\n",
    "# print(type(tfidf_vectorizer_vectors))\n",
    "good_topics = [7,11]\n",
    "for i in good_topics:\n",
    "    Kmean = KMeans(n_clusters=i, n_jobs = 10, n_init = 10)\n",
    "    predicted = Kmean.fit_predict(tfidf_vectorizer_vectors)\n",
    "    labels = Kmean.labels_\n",
    "    silhouette = metrics.silhouette_score(tfidf_vectorizer_vectors, labels, metric='euclidean')\n",
    "    print(\"Silhouette score for model\", i, \" \", silhouette)\n",
    "    # centroids = Kmean.cluster_centers_\n",
    "    print(\"Inertia: \", Kmean.inertia_)\n",
    "    model_name = 'Kmeans'+str(i) + '.model'\n",
    "    #SAVE MODEL\n",
    "    # dump(Kmean, model_name)\n",
    "    print(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# features = tfidf_vectorizer.get_feature_names()\n",
    "# print(features[i])\n",
    "# tfidf_array_format = tfidf_vectorizer_vectors.toarray()\n",
    "\n",
    "\n",
    "#For understanding output\n",
    "# for i in range(NUMBER_OF_FILES):\n",
    "#     row = tfidf_array_format[i]\n",
    "#     topn_ids = np.argsort(row)[::-1][:20]\n",
    "#     # print(topn_ids)\n",
    "#     # print(row[topn_ids[0]])\n",
    "#     top_feats = [(features[j], row[j]) for j in topn_ids]\n",
    "#     df = pd.DataFrame(top_feats, columns=['features', 'score'])\n",
    "#     print(\"Top 20 words and scores in document: \")\n",
    "#     print(df)\n",
    "# # cosine_similarities = sk.cosine_similarity(tfidf_array_format)\n",
    "# # print(\"Printing cosine cosine_similarities pairwise:\")\n",
    "# # print(cosine_similarities)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
